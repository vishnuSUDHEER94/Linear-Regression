{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbotfinalll.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jonNuJJgT_hN",
        "colab_type": "code",
        "outputId": "3d93fb11-a1af-4f2b-cc93-be774aac42f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "# importing the natural language tool kit\n",
        "import nltk\n",
        "# needed for tokenizing the dataset\n",
        "nltk.download('punkt')\n",
        "# importing the regular expression\n",
        "import re\n",
        "# importing the numpy library to work with and manipulate the data\n",
        "import numpy as np\n",
        "# import the pandas library to read our dataset\n",
        "import pandas as pd\n",
        "# importing the sys library which can perform introspection about the system \n",
        "import sys\n",
        "# importing the os library to interact with our operating system\n",
        "import os\n",
        "# importing the load_model and model\n",
        "from keras.models import load_model, Model\n",
        "# importing the Bidirectional, Dense, TimeDistributed, LSTM, Embedding and Input layers\n",
        "from keras.layers import Bidirectional, Dense, TimeDistributed, LSTM, Embedding, Input\n",
        "# setting the output length\n",
        "OUTPUT_LENGTH = 20\n",
        "# setting the output length\n",
        "INPUT_LENGTH = 20"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXPD1zZgVGp6",
        "colab_type": "code",
        "outputId": "75ec894b-c8f0-44c6-b33e-1f55f51a2124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# it is for data loading\n",
        "# Reading two .txt files \n",
        "raw_movie_lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n') # The path to .txt file\n",
        "raw_movie_conv_lines = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "# it is for mapping each line id with its corresponding text by creating a dictionary\n",
        "ansid = {}\n",
        "# reading lines from raw_movoe_lines dataset\n",
        "for line in raw_movie_lines:\n",
        "    # splitting the lines and assigning to _line\n",
        "    _line = line.split(' +++$+++ ')\n",
        "    # if the len of line is equal to 5 then the below condition executes\n",
        "    if len(_line) == 5:\n",
        "        ansid[_line[0]] = _line[4]\n",
        "# Creating a list for all the conversations lines id's \n",
        "convs = []\n",
        "# reading the lines from raw_movie_conv_lines dataset\n",
        "for line in raw_movie_conv_lines[:-1]:\n",
        "    # splitting the lines and assigning to _line\n",
        "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    # appending those splitted lines to conversations\n",
        "    convs.append(_line.split(','))\n",
        "# few set of id's and conversations \n",
        "for k in convs[300]:\n",
        "    # print the value of k\n",
        "    print (k, ansid[k])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L3490 That's what he did to me.  He put cigarettes out on me.\n",
            "L3491 Your father put cigarettes out on you?\n",
            "L3492 Out on my back when I was a small boy.\n",
            "L3493 Can I see your back?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC-1LsCvXM7i",
        "colab_type": "code",
        "outputId": "444b593d-41aa-4785-8575-37147833d248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# We need to perform the sorting operations on sentences to questions and on answers \n",
        "# For questions\n",
        "ques = []\n",
        "# For Answers\n",
        "ans = []\n",
        "# for conversation in conversations\n",
        "for conv in convs:\n",
        "    for i in range(len(conv)-1):\n",
        "        # appending the conversations ids to the questions\n",
        "        ques.append(ansid[conv[i]])\n",
        "        # appending the conversations ids to the answers\n",
        "        ans.append(ansid[conv[i+1]])\n",
        "# We need to Compare both the lengths of questions and answers\n",
        "# printing the length of the questions\n",
        "print(len(ques))\n",
        "# printing the length of the answers\n",
        "print(len(ans))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "221616\n",
            "221616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKB1GEgAYNog",
        "colab_type": "code",
        "outputId": "8477de1b-35a6-4595-f807-6934b6436048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# A method for cleaning the text \n",
        "def clean_text(text):\n",
        "    # it will be cleaning the text by removing all the unnedded characters and changing the words and characters format\n",
        "    # converting the text to the lower case letters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    # splitting the text and joining the text to the text\n",
        "    text = \" \".join(text.split())\n",
        "    # returning the text\n",
        "    return text\n",
        "# Cleaning the data which contains both questions and answers\n",
        "# For cleaning the questions\n",
        "clean_questions = []\n",
        "for question in ques:\n",
        "    # cleaning the questions and appending them to the clean_questions\n",
        "    clean_questions.append(clean_text(question))\n",
        "# For Cleaning the answers\n",
        "clean_answers = []    \n",
        "for answer in ans:\n",
        "    # cleaning the answers and appending them to the clean_answers\n",
        "    clean_answers.append(clean_text(answer))\n",
        "# After performing the clean opeartion on both questions and answers we need to find the length of the sentence\n",
        "# We are finding the length of sentences and we are not using the natural language tool kit during this process\n",
        "senlen = []\n",
        "for question in clean_questions:\n",
        "    # splitting and finding the length of the questions and then finally append it to the senlen\n",
        "    senlen.append(len(question.split()))\n",
        "for answer in clean_answers:\n",
        "    # splitting and finding the length of the answers and then finally append it to the senlen\n",
        "    senlen.append(len(answer.split()))\n",
        "# Need to create a dataframe which can be helpful in inspecting the values\n",
        "senlen = pd.DataFrame(senlen, columns=['counts'])\n",
        "print(np.percentile(senlen, 80))\n",
        "print(np.percentile(senlen, 85))\n",
        "print(np.percentile(senlen, 90))\n",
        "print(np.percentile(senlen, 95))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16.0\n",
            "19.0\n",
            "24.0\n",
            "32.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4V7epcpazbF",
        "colab_type": "code",
        "outputId": "5f286de9-89f9-4a42-cf1b-4048dcdabd11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# We need to remove both question and answers that are shorter than 1 word and larger than 20 words\n",
        "# so minimum length is 2\n",
        "minimum_length = 2\n",
        "# so maximum length is 20\n",
        "maximum_length = 20\n",
        "# Then filter the question and answer that are too short (or) long\n",
        "short_ques = []\n",
        "short_ans = []\n",
        "# for both index i and question in clean_questions\n",
        "for i, question in enumerate(clean_questions):\n",
        "    # checking the condition for length of the question is greater or equal to minimum_length and less than or equal to maximum_length \n",
        "    if len(question.split()) >= minimum_length and len(question.split()) <= maximum_length:\n",
        "        # if the condition is true\n",
        "        # then append the question to short questions\n",
        "        short_ques.append(question)\n",
        "        # if the condition is true\n",
        "        # then append the answers to the short answers\n",
        "        short_ans.append(clean_answers[i])\n",
        "short_qu = []\n",
        "short_an = []\n",
        "# for both index i and answer in short_answers\n",
        "for i, answer in enumerate(short_ans):\n",
        "    # checking the conditon for the length of the answer is greater or equal to minimum_length and less than or equal to maximum_length\n",
        "    if len(answer.split()) >= minimum_length and len(answer.split()) <= maximum_length:\n",
        "        # if the condition is true\n",
        "        # then append the answer to short answers\n",
        "        short_an.append(answer)\n",
        "        # if the condition is true\n",
        "        # then append the question to short questions\n",
        "        short_qu.append(short_ques[i])\n",
        "# printing the length of the short question               \n",
        "print(len(short_qu))\n",
        "# printing the length of the short answer\n",
        "print(len(short_an))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "139603\n",
            "139603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwlXJ3i3d0YG",
        "colab_type": "code",
        "outputId": "a3b75444-6470-4382-9498-1c87e8e95261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# np.random.randint is used for returning the random integers \n",
        "r = np.random.randint(1,len(short_qu))\n",
        "for i in range(r, r+3):\n",
        "    # printing the short questions\n",
        "    print(short_qu[i])\n",
        "    # printing the short answers\n",
        "    print(short_an[i])\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jillie, you want a cheese grilled sandwich?\n",
            "it is called a grilled cheese sandwich, you dub.\n",
            "\n",
            "his office. you mean my old office.\n",
            "well, i guess -- that is what he said.\n",
            "\n",
            "well, i guess -- that is what he said.\n",
            "he got his deer yet?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SadE5y0Cei1R",
        "colab_type": "code",
        "outputId": "bd767659-e4f0-44b8-a922-f779b66ff708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Preprocessing for word based model \n",
        "#choosing the number of samples for training\n",
        "num_samples = 30000 \n",
        "# Number of samples for short questions \n",
        "short_qu = short_qu[:num_samples]\n",
        "# Number of samples to short answers\n",
        "short_an = short_an[:num_samples]\n",
        "# Applying the tokenizing on questions\n",
        "questions_tokenize = [nltk.word_tokenize(sent) for sent in short_qu]\n",
        "# Applying the tokenizing on answers\n",
        "answers_tokenize = [nltk.word_tokenize(sent) for sent in short_an]\n",
        "\n",
        "# splitting the training and validation\n",
        "# assigning the length of the tokenized questions to the value\n",
        "size_of_the_data = len(questions_tokenize)\n",
        "# We are using 80 percent of the data for the training and assigning it to the input_train_data\n",
        "input_train_data  = questions_tokenize[:round(size_of_the_data*(80/100))]\n",
        "# We are reverseing the input sequence for a good performance\n",
        "input_train_data  = [tr_input[::-1] for tr_input in input_train_data]\n",
        "# assigning value to the output trained data \n",
        "output_train_data = answers_tokenize[:round(size_of_the_data*(80/100))]\n",
        "# remaining 20% of the data is used for validations\n",
        "# assigning the value to the input_validating_data\n",
        "input_validating_data = questions_tokenize[round(size_of_the_data*(80/100)):]\n",
        "# We are reverseing the input sequence for a good performance\n",
        "input_validating_data  = [val_input[::-1] for val_input in input_validating_data]\n",
        "# assigning the value to the output_validating_data\n",
        "output_validating_data = answers_tokenize[round(size_of_the_data*(80/100)):]\n",
        "# printing the size of the training data\n",
        "print('The size of the training data', len(input_train_data))\n",
        "# printing the size of the validation data\n",
        "print('The size of the validation data', len(input_validating_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the training data 24000\n",
            "The size of the validation data 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Q3Meq_hPbA",
        "colab_type": "code",
        "outputId": "95a1494d-d0d5-4378-e37a-88b713adbf9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# For vocabulary frequency we are creating a dictionary\n",
        "vocabulary = {}\n",
        "# for questions in questions_tokenize\n",
        "for question in questions_tokenize:\n",
        "    # for word in the question\n",
        "    for word in question:\n",
        "        # checking the condition if the word is not present in the vocabulary then assign 1\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = 1\n",
        "        # if the word is present in the vocabulary then else part should get assigned\n",
        "        else:\n",
        "            vocabulary[word] += 1\n",
        "# for answer in answers_tokenize\n",
        "for answer in answers_tokenize:\n",
        "    # for word in answer\n",
        "    for word in answer:\n",
        "         # checking the condition if the word is not present in the vocabulary then assign 1\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = 1\n",
        "        # if the word is present in the vocabulary then else part should get assigned\n",
        "        else:\n",
        "            vocabulary[word] += 1\n",
        "# We have to remove the rare words from the vocabulary and replace lesser than 5% of words with <UNK>\n",
        "# assign thresholdvalue to 15\n",
        "thresholdvalue = 15\n",
        "# assign count to 0\n",
        "count = 0\n",
        "for k,v in vocabulary.items():\n",
        "    # checking the condition if v is greater or equal to the thresholdvalue, then count gets increment\n",
        "    if v >= thresholdvalue:\n",
        "        count += 1\n",
        "# printing the total size of the vocabulary       \n",
        "print(\"Size of total vocabulary:\", len(vocabulary))\n",
        "# printing thr size of vocabulary in use\n",
        "print(\"Size of vocabulary we will use:\", count)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of total vocabulary: 16616\n",
            "Size of vocabulary we will use: 1959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFDWFPZEjZob",
        "colab_type": "code",
        "outputId": "7a486e1a-455d-47e7-e7d4-4b2f3efe2565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# assign word_start to 1\n",
        "WORD_START = 1\n",
        "# assign word_padding to 0\n",
        "WORD_PADDING = 0\n",
        "# assign numberofword to 2\n",
        "numberoftheword  = 2\n",
        "# for encoded_data\n",
        "encoded_data = {}\n",
        "# for decoded_data\n",
        "decoded_data = {1: 'START'}\n",
        "# for word and count in vocabulary.items()\n",
        "for word, count in vocabulary.items():\n",
        "    # checking the condition if count is greater or equal to the thresholdvalue\n",
        "    if count >= thresholdvalue: \n",
        "        encoded_data[word] = numberoftheword \n",
        "        decoded_data[numberoftheword ] = word\n",
        "        numberoftheword += 1\n",
        "# printing the total number of vocabulary used\n",
        "print(\"Total number of vocabulary used:\", numberoftheword)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of vocabulary used: 1961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faJx7X47kYch",
        "colab_type": "code",
        "outputId": "7d7561c1-51cf-43c4-bd85-202ed65b16c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Dictionares are created which helps in providing the different integer for each and every word\n",
        "# including the unknown tokens for words and not for dictionary\n",
        "decoded_data[len(encoded_data)+2] = '<UNK>'\n",
        "encoded_data['<UNK>'] = len(encoded_data)+2\n",
        "# assigning the values to the dictionary_size\n",
        "dictionary_size = numberoftheword+1\n",
        "dictionary_size"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzE2oxFimMxW",
        "colab_type": "code",
        "outputId": "ead02e6a-63c5-45d9-fe06-5d39bb60f416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Vectorizing the dataset\n",
        "# method for data transformation with inputs encoded_data and sizeofthevector\n",
        "# size of the vector is 20\n",
        "def datatransformation(encoded_data, data, sizeofthevector=20):\n",
        "    datatransformed = np.zeros(shape=(len(data), sizeofthevector))\n",
        "    # for i in the range of the data length\n",
        "    for i in range(len(data)):\n",
        "        # for j in the range of minimum length of the data\n",
        "        for j in range(min(len(data[i]), sizeofthevector)):\n",
        "            try:\n",
        "                datatransformed[i][j] = encoded_data[data[i][j]]\n",
        "            except:\n",
        "                datatransformed[i][j] = encoded_data['<UNK>']\n",
        "    # returning the datatransformed\n",
        "    return datatransformed\n",
        "\n",
        "# encoding the data training set\n",
        "# assigning the input trained data\n",
        "inputtrainingencoded = datatransformation(encoded_data, input_train_data, sizeofthevector=INPUT_LENGTH)\n",
        "# assigning the output trained data\n",
        "outputtrainingencoded = datatransformation(encoded_data, output_train_data, sizeofthevector=OUTPUT_LENGTH)\n",
        "# printing the input trained data\n",
        "print('The input training encoded value is:', inputtrainingencoded.shape)\n",
        "# printing the output trained data\n",
        "print('The output training encoded value is', outputtrainingencoded.shape)\n",
        "\n",
        "#encoding the data validation set\n",
        "# assigning the input validation data\n",
        "inputvalidationencoded = datatransformation(encoded_data, input_validating_data, sizeofthevector=INPUT_LENGTH)\n",
        "# assigning the output validation data\n",
        "outputvalidationencoded = datatransformation(encoded_data, output_validating_data, sizeofthevector=OUTPUT_LENGTH)\n",
        "# printing the input validation data\n",
        "print('The input validation encoded value is:', inputvalidationencoded.shape)\n",
        "# printing the output validation data\n",
        "print('The output validation encoded value is :', outputvalidationencoded.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input training encoded value is: (24000, 20)\n",
            "The output training encoded value is (24000, 20)\n",
            "The input validation encoded value is: (6000, 20)\n",
            "The output validation encoded value is : (6000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEjNWnmuofec",
        "colab_type": "code",
        "outputId": "12291eed-f80f-4eda-8b20-4f40be3337bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# installing the tensorflow version of 1.14.0\n",
        "!pip install tensorflow==1.14.0\n",
        "# importing the tensorflow library\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8V5FC1Mol4q",
        "colab_type": "code",
        "outputId": "1fa8730c-aaab-4393-8317-d7089273f142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Building the model\n",
        "# sequence-to-sequence operation in keras\n",
        "# assigning the input_length to 20\n",
        "INPUT_LENGTH = 20\n",
        "# assigning the output_length to 20\n",
        "OUTPUT_LENGTH = 20\n",
        "# assigning the value to encodedinput\n",
        "encodedinput = Input(shape=(INPUT_LENGTH,))\n",
        "# assigning the value to decodedinput\n",
        "decodedinput = Input(shape=(OUTPUT_LENGTH,))\n",
        "\n",
        "# import SimpleRNN from keras.layers\n",
        "from keras.layers import SimpleRNN\n",
        "# assigning the Embedding layer and its parameters to the encoding\n",
        "encoding = Embedding(dictionary_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encodedinput)\n",
        "# assigning the LSTM layer and its parameters to the encoding\n",
        "encoding = LSTM(512, return_sequences=True, unroll=True)(encoding)\n",
        "# assigning the value to the lastencoding\n",
        "lastencoding = encoding[:,-1,:]\n",
        "# printing the encoding value\n",
        "print('encoding', encoding)\n",
        "# printing the lastencoding value\n",
        "print('lastencoding', lastencoding)\n",
        "# assigning the Embedding layer and its parameters to the decoding\n",
        "decoding = Embedding(dictionary_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decodedinput)\n",
        "# assigning the LSTM layer and its parameters to the decoding\n",
        "decoding = LSTM(512, return_sequences=True, unroll=True)(decoding, initial_state=[lastencoding, lastencoding])\n",
        "# printing the decoding value\n",
        "print('decoding', decoding)\n",
        "\n",
        "# import dot, concatenate and activation from keras.layers\n",
        "from keras.layers import dot, concatenate, Activation\n",
        "# assigning the value to the layerss\n",
        "layerss = dot([decoding, encoding], axes=[2, 2])\n",
        "layerss = Activation('softmax', name='layerss')(layerss)\n",
        "# printing the layerss value\n",
        "print('layerss', layerss)\n",
        "layersss = dot([layerss, encoding], axes=[2,1])\n",
        "# printing the layerss value\n",
        "print('layerss', layerss)\n",
        "concatenate_context = concatenate([layerss, decoding])\n",
        "# printing the convatenate_context value\n",
        "print('concatenate_context', concatenate_context)\n",
        "# assigning the Dense layer and its parameters to the olayer with tanh activation function\n",
        "olayer = TimeDistributed(Dense(512, activation=\"tanh\"))(concatenate_context)\n",
        "# assigning the Dense layer and its parameters to the olayer with softmax activation function\n",
        "olayer = TimeDistributed(Dense(dictionary_size, activation=\"softmax\"))(olayer)\n",
        "# printing the olayer value\n",
        "print('olayer', olayer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3156: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "encoding Tensor(\"lstm_1/transpose_2:0\", shape=(?, 20, 512), dtype=float32)\n",
            "lastencoding Tensor(\"strided_slice:0\", shape=(?, 512), dtype=float32)\n",
            "decoding Tensor(\"lstm_2/transpose_2:0\", shape=(?, 20, 512), dtype=float32)\n",
            "layerss Tensor(\"layerss/truediv:0\", shape=(?, 20, 20), dtype=float32)\n",
            "layerss Tensor(\"layerss/truediv:0\", shape=(?, 20, 20), dtype=float32)\n",
            "concatenate_context Tensor(\"concatenate_1/concat:0\", shape=(?, 20, 532), dtype=float32)\n",
            "olayer Tensor(\"time_distributed_2/Reshape_1:0\", shape=(?, 20, 1962), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDuRrGeLrpaO",
        "colab_type": "code",
        "outputId": "034d8b38-5bb5-42ac-b00b-4bc33fedb2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# assigning the Model and its parameters to the mtrain model variable\n",
        "mtrain = Model(inputs=[encodedinput, decodedinput], outputs=[olayer])\n",
        "# compile the mtrain model with adam optimizer and binary_crossentropy loss\n",
        "mtrain.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summary of the mtrain model\n",
        "mtrain.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 20, 128)      251136      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 128)      251136      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 20, 512)      1312768     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 20, 512)      1312768     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 20, 20)       0           lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layerss (Activation)            (None, 20, 20)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 20, 532)      0           layerss[0][0]                    \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 20, 512)      272896      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 20, 1962)     1006506     time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 4,407,210\n",
            "Trainable params: 4,407,210\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU1kXtptsO4O",
        "colab_type": "code",
        "outputId": "cf7c4116-e592-44c4-9167-cdbf3917762a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# assigning inputtrainingencoded to inputencodingtraining\n",
        "inputencodingtraining = inputtrainingencoded\n",
        "inputdecodingtraining = np.zeros_like(outputtrainingencoded)\n",
        "inputdecodingtraining[:, 1:] = outputtrainingencoded[:,:-1]\n",
        "# WORD_START to inputdecodingtraining\n",
        "inputdecodingtraining[:, 0] = WORD_START\n",
        "outputdecodingtraining = np.eye(dictionary_size)[outputtrainingencoded.astype('int')]\n",
        "# assigning inputvalidationencoded to inputencodingvalidation\n",
        "inputencodingvalidation = inputvalidationencoded\n",
        "inputdecodingvalidation = np.zeros_like(outputvalidationencoded)\n",
        "inputdecodingvalidation[:, 1:] = outputvalidationencoded[:,:-1]\n",
        "# assigning WORD_START to inputdecodingvalidation\n",
        "inputdecodingvalidation[:, 0] = WORD_START\n",
        "outputdecodingvalidation = np.eye(dictionary_size)[outputvalidationencoded.astype('int')]\n",
        "\n",
        "# assigning the batch_size=128, epochs=5 to mtrain model\n",
        "#history=mtrain.fit(x=[inputencodingtraining, inputdecodingtraining], y=[outputdecodingtraining],validation_data=([inputencodingvalidation, inputdecodingvalidation], [outputdecodingvalidation]),batch_size=128, epochs=2)\n",
        "history=mtrain.fit(x=[inputencodingtraining, inputdecodingtraining], y=[outputdecodingtraining],batch_size=64, epochs=5)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/5\n",
            "24000/24000 [==============================] - 321s 13ms/step - loss: 0.0031 - acc: 0.9995\n",
            "Epoch 2/5\n",
            "24000/24000 [==============================] - 312s 13ms/step - loss: 0.0027 - acc: 0.9995\n",
            "Epoch 3/5\n",
            "24000/24000 [==============================] - 311s 13ms/step - loss: 0.0025 - acc: 0.9995\n",
            "Epoch 4/5\n",
            "24000/24000 [==============================] - 314s 13ms/step - loss: 0.0024 - acc: 0.9995\n",
            "Epoch 5/5\n",
            "24000/24000 [==============================] - 314s 13ms/step - loss: 0.0024 - acc: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN6skHQCHjpm",
        "colab_type": "code",
        "outputId": "e1f41eed-555b-41b1-c38f-c6fadf905bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "#history_df[['loss', 'val_loss']].plot()\n",
        "#history_df[['acc', 'val_acc']].plot()\n",
        "history_df[['loss']].plot() #Like so.\n",
        "history_df[['acc']].plot()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f230bda8eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD4CAYAAAA6j0u4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwwRE1KBteV-",
        "colab_type": "code",
        "outputId": "da72ec89-1f2d-462d-b914-6f4dce9275c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# importing the load_model from keras.models\n",
        "from keras.models import load_model\n",
        "# It creates a HDF5 file\n",
        "mtrain.save('9_project2_TT.h5')\n",
        "# Deletes the model that currently exists\n",
        "del mtrain\n",
        "# loads the model\n",
        "mtrain = load_model('9_project2_TT.h5')\n",
        "mtrain.summary()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:883: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'strided_slice:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'strided_slice:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 20, 128)      251136      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 128)      251136      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 20, 512)      1312768     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 20, 512)      1312768     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 20, 20)       0           lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "layerss (Activation)            (None, 20, 20)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 20, 532)      0           layerss[0][0]                    \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 20, 512)      272896      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 20, 1962)     1006506     time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 4,407,210\n",
            "Trainable params: 4,407,210\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrMTeRD1Q8kj",
        "colab_type": "code",
        "outputId": "529786b7-51ed-4e4e-b259-082046550426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#input_validating_data= input_validating_data.reshape(input_validating_data.shape[0], input_validating_data.shape[1], 1)\n",
        "#output_validating_data = output_validating_data.reshape(output_validating_data.shape[0], output_validating_data.shape[1], 1)\n",
        "#import numpy as np\n",
        "x_train_np = np.array(inputencodingvalidation)\n",
        "y_train_np = np.array(output_validating_data)\n",
        "x_test = np.expand_dims(x_train_np, axis=2)\n",
        "acc = mtrain.evaluate(x=[inputencodingvalidation, inputdecodingvalidation],y= [outputdecodingvalidation], verbose=0)\n",
        "print(\"Accuracy\"+str(acc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy[0.002499713831891616, 0.9995172135035197]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywVZHSVnt5vp",
        "colab_type": "code",
        "outputId": "25bac623-9895-4823-eadd-28ee68b0796d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "# method for predicting the raw input with the rawdata\n",
        "def predictingrawinput(rawdata):\n",
        "    # cleaning the rawdata\n",
        "    clean_textt = clean_text(rawdata)\n",
        "    # applying the tokenization on the cleaned text\n",
        "    inputtokenization = [nltk.word_tokenize(clean_textt)]\n",
        "    # The input sequence is reveersed\n",
        "    inputtokenization = [inputtokenization[0][::-1]] \n",
        "    # Data transfromation on encoded input\n",
        "    encodedinput = datatransformation(encoded_data, inputtokenization, 20)\n",
        "    decodedinput = np.zeros(shape=(len(encodedinput), OUTPUT_LENGTH))\n",
        "    # assigning the WORD_START to the decodedinput\n",
        "    decodedinput[:,0] = WORD_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        olayer = mtrain.predict([encodedinput, decodedinput]).argmax(axis=2)\n",
        "        decodedinput[:,i] = olayer[:,i]\n",
        "    # returning the olayer\n",
        "    return olayer\n",
        "# method for decoding the text with the decode_data and vectorization\n",
        "def decodingtext(decoded_data, vectorization):\n",
        "    text = ''\n",
        "    # for in in vectorization\n",
        "    for i in vectorization:\n",
        "        # checking the if condition for i equal to zero\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoded_data[i]\n",
        "    # returning the text\n",
        "    return text\n",
        "# for in in the range of 20    \n",
        "for i in range(20):\n",
        "    # assigning the value to the sequentialindex\n",
        "    sequentialindex = np.random.randint(1, len(short_qu))\n",
        "    # assigning the value to the olayer\n",
        "    olayer = predictingrawinput(short_qu[sequentialindex])\n",
        "    # printing the question :\n",
        "    print ('Questions Pls:', short_qu[sequentialindex])\n",
        "    # printing the answer :\n",
        "    print ('Your Answer:', decodingtext(decoded_data, olayer[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Questions Pls: dongt you open your messages?\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: thanks for the invite.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: colonel finck, are you saying someone told you not to dissect the neck?\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: stop it! stop it! it hurts!\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: wow. look at the mountains.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: more... many more.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: why know?\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: good morning, mr. bebe!\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: roll him over!\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: you look awful.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: ten reasons. maybe fifteen. and also there's something in it for me.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: you kidding? this is detroit. drink?\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: these are worth at least, i dongt know --\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: that is the corrected bearing to the magnetic pole?\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: always good advice.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: let us get to the border!\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: about cholesterol...you know what i know, you would have the seafood.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: far enough. maybe up to san francisco. or st. louis, someplace new. start over.\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: \"make\" him?\n",
            "Your Answer:  i am not <UNK> .\n",
            "Questions Pls: manray was under our nose the whole time.\n",
            "Your Answer:  i am not <UNK> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqZc50u1vr4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dc389040-e743-406b-e885-1e3fa73ab2ff"
      },
      "source": [
        "# assigning the input() to the rawdata\n",
        "rawdata = input()\n",
        "# assigning the rawdata to the olayer\n",
        "olayer = predictingrawinput(rawdata)\n",
        "# printing the decodingtext\n",
        "print (decodingtext(decoded_data, olayer[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi\n",
            " i am not <UNK> .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}